\section{Introduction} 
%In hardware we are limited to one layer neural network (Perceptron). Perceptron can only learn linearly separable functions.  
% showed that using carefully selected detailed microarchitectural features and a simple  single-layered perceptron can provide a readily implementable solution. 

The performance of modern processors is heavily dependent on prediction and speculative execution throughout the pipeline.  Speculative execution, however has recently shown itself to be a two edged sword with the disclosure in early 2018 of microarchitectural attacks such as Spectre and Meltdown~\cite{spectre, meltdown}. The total cost to secure each component individually against all potential microarchitectural attack variations incur increasingly high cost in real estate, performance and energy~\cite{canella2018systematic, schwarz2019zombieload}, giving us an unsatisfying choice between expensive software mitigations or turning off these performance features altogether.  

 
Several of the mitigation either impose high performance overhead
to the system and/or only mitigate a specific variant
~\cite{taram_csf19, intelanalysis, kiriansky2018dawg, domnitser2012non,saileshwar2019cleanupspec,retpoline, wang2007new, yu2019speculative, yan2018invisispec,CEASER,amd, koruyeh2019speccfi, arm_css}
Detection mechanisms can provide information to the system to trigger further
mitigations to avoid their overhead unless an attack is suspected~\cite{gulmezoglu2019fortuneteller, PerSpectron, cyclone2019}.
Prior works have detected microarchitectural attacks through two methods: Tracking unique cyclic properties in hardware ~\cite{cyclone2019} which can detect after the leakage completed, or detecting specific microarchitectural footprints of attacks using machine learning in hardware~\cite{PerSpectron, RHMD2017} and in software~\cite{gulmezoglu2019fortuneteller, cacheBasedDetection2016Chiappetta,
CloudRadar2016,
BlackHatFogh,
payer2016hexpads,
ICCAD2015Wang,
Duppel2013Zhang, 
mushtaq:cel-01824512}. 

Using machine learning enables detection before the attack can be successful, including detection of calibration phases required for attacks, training phases, etc. 
However, this presents a particularly difficult
problem for simulation-to-real-world transfer: %besides the targeted vulnerable components of hardware changing in each variations of these attacks,
the detection
system must also handle {\em evasive attacks} which poses multiple challenges for designing a resilient detector, specially resiliency against {\em adversarial machine learning attacks}. There are three main categories of evasion techniques: (1) bandwidth reduction (2) polymorphic evasion and (3) adversarial machine learning attacks.   

 
Software detectors have high performance overhead due to sampling and are also prone to bandwidth evasion~\cite{Gaudiot2020, PerSpectron}. Bandwidth evasion is based on timing the completion of all attack atomic 
tasks to fit within the sampling interval. Recent studies~\cite{PerSpectron, cyclone2019} on detection of transient, MDS and cache attacks and malware~\cite{Malware2015, ensembleRaid2015,kazdagli-16,RHMD2017} addressed the software limitations by moving the detection of
attacks to hardware, allowing thousand-times higher sampling frequency (100ms vs 1$\mu$s) without incurring performance overhead. It would be very difficult for the attacker to implement an microarcitectural attack atomic phase requiring an interval under three microseconds. 

Detection in hardware does not only make evasion based on bandwidth reduction very hard, but it is also shown to make detection more robust against polymorphic evasions~\cite{PerSpectron, cyclone2019, RHMD2017}. Polymorphic attacks is when the attacker attempts to produce different binaries implementing the attack. Because in microarchitectural attacks, attacker can implement instructions that will never get itâ€™s result committed to the registers but force the CPU to execute instructions and leak data, it is important for security solutions 
to be able to detect attacks in the speculative execution feature 
space~\cite{wampler-19, PerSpectron}. 



Detection in hardware also allows the predictor to efficiently use and monitor a large set of informative microarchitectural features that is not . Recent study~\cite{PerSpectron} shows that low-level  features that are not limited to the committed instructions exist that are invariant under transformation and evasions by typical strategies
used by malware to evade signature based detectors~\cite{PaulKocher,paulKocherSpectreAttacks} and are accessible from hardware. 

The ability to use high number of features in hardware without incurring performance overhead makes adversarial machine learning attacks
described in prior hardware malware detector is potentially prohibitively expensive against hardware detectors.
However, few studies have conclusively studied methods to increase robustness of  microarchitectural attack detectors in hardware against adversarial machine learning attacks. 


Designing such a system in hardware poses multiple challenges: First, often handcrafted adversarial attacks, and even real microarchitectural attack data are not sufficient for training and evaluation of a robust and reliable detector: While at least 350,000 new malware instances are being created and detected every day, microarchitectural attacks were reported only over 20 distinct attack variations. 
Previous detection mechanisms for microarchitectural attacks are trained and evaluated only on small samples, e.g., proof of concept code of current Spectre attacks and limited hand crafted adversarial perturbation similar to typical strategy 
used by malware to evade signature based
detectors~\cite{PaulKocher,paulKocherSpectreAttacks}. No teams of human can realistically design enough adversarial training data for ML-based microarchitectural attack detectors.



Second, while augmenting the training dataset with adversarial examples~\cite{szegedy2014going, Goodfellow2015ADVexample, moosavidezfooli2016deepfool} has been proven to almost always improve the accuracy of machine learning detectors in other domains such as image classification, projecting the adversarial perturbation to the program  is not trivial in microarchitectural attacks. More importantly, there is no direct mapping from microarchitectural features value to program instructions (software code).   
 Thus, generating adversarial microarchitectural attack manually is  expensive and cumbersome, often requiring days for developing a single adversarial example that would fool a robust detector {\em i.e.,} to leak data before the detector flags it as suspicious.


The science of defenses for machine learning based  detection in hardware against evasive attacks are somewhat less well developed. This is the main reason for low confidence in ML-based detection systems in hardware against microarchitectural attacks. In this paper we contribute on several defensive goals:

\begin{enumerate}
\item We present the first use of adversarial learning to improve the
design of hardware detectors for microarchitectural attacks. 
\vspace{2mm}

\item We design the first asymmetric  adversarial perceptron training, in which a one layer neural network that is amenable in hardware, can be trained by a more complex deep neural network in software.
\vspace{2mm}

\item We use the trained perceptron and a novel weight clipping technique to produce \scheme{} which (1) significantly improves detection accuracy for broad range of microarchitectural attacks against evasive and adversarial machine learning attacks, and (2) it can be built in hardware with minimal performance and area overhead. 
\end{enumerate}
