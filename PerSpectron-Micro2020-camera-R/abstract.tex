\begin{abstract}
\textcolor{red}{DMT: Title: 1. I think it works grammatically better without the "An".  2. I think it may
bury the main point a little.  The big point is better attack detection.  So something like " evasion-resistant attack detector using adversarial...", maybe? [caveat -- I haven't read enough of
the paper yet to know if this is a substantiated claim]}
Microarchitectural attack detection in hardware is attracting
increased research interest in recent years.  It has shown many advantages over software detection, such as low performance overhead, access to a larger set of detailed microarchitectural features, and greater robustness to multiple evasion techniques. The use of machine learning in hardware enables detection of attacks prior to leakage, which is essential. 
However,  defenses for hardware detectors against adversarial machine learning attacks have not been investigated, resulting in low confidence in the viability of implementing ML-based detection systems in hardware against microarchitectural attacks.

In this paper, we propose a non-injection and non-perturbation base transformation framework that generates microarchitectural attack samples 
from class conditioned generative adversarial networks.
Prior research has shown that training a classification model on augmented adversarial examples almost always improves the classifier's accuracy. 
Most adversarial example generation strategies in malware are based on developing a dynamic system that extrapolates
appropriate perturbations from benign data and adds them back onto those data based on the reverse-engineered model. We show that augmenting training sets with examples generated by conventional approaches, does not improve the detector resiliency against adversarial machine learning attacks.  Such augmentation fails because attacks perturbed from existing malware generate attacks that too closely resemble their unperturbed version and are not proved to fool hardware detectors and obviously limit the adversarial diversity.
 We overcome this problem with {\scheme}, a novel perceptron learning technique based on generative adversarial network theory~\cite{goodfellow2014generative} in which a perceptron-based detector is set up to play an adversarial game against a Deep Neural Network.  
 
 We then introduce dynamic perceptron weight clipping during adversarial training which ensures that the model does not rely on specific
features or unit of pipeline and to reduce the transferability of
the final classification parameter. Our final design significantly improves accuracy over state-of-art hardware detector for microarchitectural attacks (PerSpectron) with no extra hardware and performance overhead. Since perceptron has already been implemented in modern processors, 
our final design is readily implementable in hardware. 

%Traditional  approaches can be roughly split into to two classes, i


\end{abstract}